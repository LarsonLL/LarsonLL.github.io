<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-04-13T11:38:10.000Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Refresh Materialized View</title>
    <link href="http://example.com/2022/04/13/Refresh-Materialized-View/"/>
    <id>http://example.com/2022/04/13/Refresh-Materialized-View/</id>
    <published>2022-04-13T11:36:38.000Z</published>
    <updated>2022-04-13T11:38:10.000Z</updated>
    
    <content type="html"><![CDATA[<font face="黑体"><h1 id="refer-to"><a class="markdownIt-Anchor" href="#refer-to"></a> refer to</h1><p>Oracle 官方文档 Url : <a href="https://docs.oracle.com/cd/E11882_01/server.112/e25554/refresh.htm#DWHSG03003">https://docs.oracle.com/cd/E11882_01/server.112/e25554/refresh.htm#DWHSG03003</a></p><h1 id="概述"><a class="markdownIt-Anchor" href="#概述"></a> 概述</h1><p>在创建 materialized view 的时候可以指定两种刷新方式</p><ul><li>ON COMMIT<br />在这种机制下，Materialized view 在每次commit 的时候都会自动 refresh。</li><li>ON DEMAND<br />在这中case下，Materialized view 只能通过call DBMS_MVIEW 这个package中的procedure才能进行refresh</li></ul><p>DBMS_MVIEW 提供3种刷新方式</p><ul><li>DBMS_MVIEW.REFRESH  # 刷新一个或者多个物化视图</li><li>DBMS_MVIEW.REFRESH_ALL_MVIEWS  # 刷新所有的物化视图</li><li>DBMS_MVIEW.REFRESH_DEPENDENT  # 刷新所有依赖于指定的主表、物化视图（可以是多个）的物化视图</li></ul><h4 id="font-colorred-size6-note-font"><a class="markdownIt-Anchor" href="#font-colorred-size6-note-font"></a> <font color=red size=6 > Note: </font></h4><ul><li>由于刷新物化视图操作需要临时空间来重建索引，并且可能需要额外的空间来执行刷新操作本身，所以不需要频繁的进行刷新操作。因此如果没有及时刷新物化视图的话，需要考虑查询重写的问题。</li><li>可以通过 <code>ALTER SYSTEM SET QUERY_REWRITE_ENABLED = FALSE or TRUE</code> 来禁用或者启用查询重写操作。</li><li>Oracle 版本 10 以下 默认为fales ， 10 以上 为TRUE</li><li>If you anticipate performing insert, update or delete operations on tables referenced by a materialized view concurrently with the refresh of that materialized view, and that materialized view includes joins and aggregation, Oracle recommends you use ON COMMIT fast refresh rather than ON DEMAND fast refresh.(如果预计在物化视图刷新的同时对物化视图引用的表执行插入，更新或删除操作，并且该物化视图包含连接和聚合，Oracle建议您使用ON COMMIT快速刷新而不是ON DEMAND快速刷新。)</li></ul><h1 id="refresh-method-4种"><a class="markdownIt-Anchor" href="#refresh-method-4种"></a> Refresh method (4种)</h1><h2 id="complete-refresh"><a class="markdownIt-Anchor" href="#complete-refresh"></a> Complete Refresh</h2><ul><li>build immediate 在物化视图第一次创建的时候会发生完全刷新，除非创建的物化视图引用的表还没有被创建.</li><li>build deferred  创建的物化视图，第一时间是不会进行完全刷新，但必须在第一次使用之前进行一次完整的刷新.</li><li>刷新过程需要读取细节表，计算物化视图结果，非常耗时，尤其是当需要读取大量数据时。</li></ul><h2 id="fast-refresh"><a class="markdownIt-Anchor" href="#fast-refresh"></a> Fast Refresh</h2><ul><li>对比上面的完整刷新，快速刷新物化视图不需要重新计算整个物化视图，而是将更改现有的数据，所以会比较快</li></ul><h2 id="partition-change-tracking-pct-refresh"><a class="markdownIt-Anchor" href="#partition-change-tracking-pct-refresh"></a> Partition Change Tracking (PCT) Refresh</h2><ul><li>当物化视图引用的表有分区操作的时候，只能使用快速刷新(Fast Refresh) ,但是要满足PCT 的所有条件才允许基于PC的刷新。<br />-对于没有分区的表，如果使用Fast Refresh (method =&gt; ‘F’),Oracle在执行之前会尝试基于log的快速刷新。</li><li>类似的当使用Force方法刷新的时候，Oracle 会按如下顺序选择Refresh方式: log-based fast refresh , PCT refresh , complete</li><li>当然你也可以指定PCT刷新方式（method =&gt; ‘P’）</li></ul><h2 id="on-commit-refresh"><a class="markdownIt-Anchor" href="#on-commit-refresh"></a> ON COMMIT Refresh</h2><ul><li>使用这种方法自动刷新物化视图，当事物更新了一个物化视图引用的表时，这些changes会自动刷新到对应的物化视图上。</li><li>好处是 不需要定时刷新物化视图</li><li>缺点 commit 需要的时间比较长。不过如果再数据仓库中应该不是问题，因为不太可能并发进程，所以再OLTP中要避免这种MV。</li></ul><h2 id="manual-refresh-using-the-dbms_mview-package"><a class="markdownIt-Anchor" href="#manual-refresh-using-the-dbms_mview-package"></a> Manual Refresh Using The DBMS_MVIEW package</h2><ul><li>刷新物化视图时，可以指定4中方法之一，入下图所示</li></ul><table><thead><tr><th>Refresh Option</th><th>Parameter</th><th>Description</th></tr></thead><tbody><tr><td>COMPLETE</td><td>C</td><td>通过重新计算物化视图定义的查询来刷新</td></tr><tr><td>FAST</td><td>F</td><td>通过增量地对物化视图应用更改来刷新，对于本地物化视图，它选择由优化器估计的最新方法。所考虑的刷新方法是基于日志的快速和FAST_PCT。</td></tr><tr><td>FAST_PCT</td><td>P</td><td>通过重新计算在引用的明细表中受到更改的分区影响的物化视图中的行来进行刷新。</td></tr><tr><td>FORCE</td><td>F&amp;？</td><td>先尝试快速刷新，如果不符合快速刷新条件，就会进行完全刷新。优化器选择的刷新基于日子的FAST ，FAST_PCT 和 COMPLETE</td></tr></tbody></table><h1 id="refresh-procedure-常用的3种"><a class="markdownIt-Anchor" href="#refresh-procedure-常用的3种"></a> Refresh procedure (常用的3种)</h1><h2 id="调用dbms_mviewrefresh刷新materialized-view"><a class="markdownIt-Anchor" href="#调用dbms_mviewrefresh刷新materialized-view"></a> 调用<code>DBMS_MVIEW.REFRESH</code>刷新Materialized View</h2><ul><li>如果多个物化视图一起刷新需要用逗号分割。(list&amp;tab)</li><li>刷新方法: F-Fast , P-Fast_PCT , ? - Force , C-Complete (Method)</li><li>使用回滚段 (rollback_seg) 默认为 NULL</li><li>在错误之后是否进行刷新(TRUE or FALSE)。True: 那么需要将 <code>number_of_failure</code> 设置一个失败以后刷新的次数，类似于重新请求。FALSE: 默认Refresh 在遇到第一个错误的时候就会停止，并且列表剩余的物化视图不会刷新。 （refresh_after_errors） 默认为FALSE</li><li>下面的4个参数，用来进行 replication 过程的时候，一般再数据仓库的刷新时候 依次设置为 <code>FALSE,0,0,0</code></li><li>Atomic refresh (TRUE or FALSE) atomic_refresh 默认为TRUE  TRUE: 所有的刷新操作在一个事物中完成. FALSE: 在单独的事务中刷新每个指定的物化视图。</li></ul><h4 id="for-exampl"><a class="markdownIt-Anchor" href="#for-exampl"></a> For exampl</h4><ul><li>fast refresh  MV : cal_month_sales_mv</li></ul> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DBMS_MVIEW.REFRESH(<span class="string">&#x27;CAL_MONTH_SALES_MV&#x27;</span>, <span class="string">&#x27;F&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="literal">TRUE</span>, <span class="literal">FALSE</span>, <span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>, <span class="literal">FALSE</span>);</span><br></pre></td></tr></table></figure><ul><li>多个物化视图刷新:<code>CAL_MONTH_SALES_MV</code> 完全刷新 <code>FWEEK_PSCAT_SALES_MV</code> 快速刷新</li></ul> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DBMS_MVIEW.REFRESH(<span class="string">&#x27;CAL_MONTH_SALES_MV, FWEEK_PSCAT_SALES_MV&#x27;</span>, <span class="string">&#x27;CF&#x27;</span>, <span class="string">&#x27;&#x27;</span>, </span><br><span class="line"> <span class="literal">TRUE</span>, <span class="literal">FALSE</span>, <span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>, <span class="literal">FALSE</span>);</span><br></pre></td></tr></table></figure><h4 id="font-colorred-size6-note-font-2"><a class="markdownIt-Anchor" href="#font-colorred-size6-note-font-2"></a> <font color=red size=6 > Note: </font></h4><ul><li>如果未指定refresh方法，则使用物化视图定义中指定的默认刷新方法。</li></ul><h2 id="调用dmbs_mviewrefresh_all_mviews刷新所有的materialized-view"><a class="markdownIt-Anchor" href="#调用dmbs_mviewrefresh_all_mviews刷新所有的materialized-view"></a> 调用<code>DMBS_MVIEW.REFRESH_ALL_MVIEWS</code>刷新所有的Materialized View</h2><ul><li>这个Procedure 会刷新所有的物化视图，如果其中有未成功刷新的物化视图，会返回失败的次数。</li></ul><h4 id="parameter"><a class="markdownIt-Anchor" href="#parameter"></a> Parameter</h4><ul><li>失败数量，这是一个输出的变量OUT () number_of_failures</li><li>刷新方法，F-Fast, P-Fast_PCT, ?-Force, C-Complete</li><li>在错误之后是否进行刷新(TRUE or FALSE)。True: 那么需要将 <code>number_of_failure</code> 设置一个失败以后刷新的次数，类似于重新请求。FALSE: 默认Refresh 在遇到第一个错误的时候就会停止，并且列表剩余的物化视图不会刷新。 （refresh_after_errors） 默认为FALSE，</li><li>Atomic refresh (TRUE or FALSE) atomic_refresh 默认为TRUE  TRUE: 所有的刷新操作在一个事物中完成. FALSE: 在单独的事务中刷新每个指定的物化视图。</li></ul><h4 id="for-example"><a class="markdownIt-Anchor" href="#for-example"></a> For Example</h4>  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DBMS_MVIEW.REFRESH_ALL_MVIEWS(failures,<span class="string">&#x27;C&#x27;</span>,<span class="string">&#x27;&#x27;</span>, <span class="literal">TRUE</span>, <span class="literal">FALSE</span>);</span><br></pre></td></tr></table></figure><h2 id="调用-dmbs_mviewrefresh_dependent-刷新那些依赖于特定表或者表列表的物化视图"><a class="markdownIt-Anchor" href="#调用-dmbs_mviewrefresh_dependent-刷新那些依赖于特定表或者表列表的物化视图"></a> 调用 <code>DMBS_MVIEW.REFRESH_DEPENDENT</code> 刷新那些依赖于特定表或者表列表的物化视图。</h2><h4 id="parameter-2"><a class="markdownIt-Anchor" href="#parameter-2"></a> Parameter</h4><ul><li>失败数量，这是一个输出的变量OUT (number_of_failures)</li><li>相关的表 (list&amp;tab)</li><li>刷新方法，F-Fast, P-Fast_PCT, ?-Force, C-Complete  (Method)</li><li>使用回滚段 (rollback_seg) 默认为 NULL</li><li>在错误之后是否进行刷新(TRUE or FALSE) 同上</li><li>Atomic refresh (TRUE or FALSE) atomic_refresh 默认为TRUE 同上</li><li>是否嵌套 nested 默认为 FALSE 。 如果是TRUE 会根据依赖项顺序刷新指定表集的所有相关物化视图，以确保物化视图相对于底层基表而言是新鲜的。</li></ul><h4 id="for-example-2"><a class="markdownIt-Anchor" href="#for-example-2"></a> For Example</h4><pre><code><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">    DBMS_MVIEW.REFRESH_DEPENDENT(failures, <span class="string">&#x27;CUSTOMERS&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="literal">FALSE</span>, <span class="literal">FALSE</span> );</span><br><span class="line">    ```  </span><br><span class="line"></span><br><span class="line"># 附录</span><br><span class="line">## 如何确定物化视图是否可以进行快速刷新</span><br><span class="line">  <span class="operator">-</span> `DBMS_ADVISOR.TUNE_MVIEW` </span><br><span class="line"></span><br><span class="line">## 监控执行的刷新</span><br><span class="line">  ```<span class="keyword">sql</span></span><br><span class="line">  <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> V$SESSION_LONGOPS;</span><br><span class="line">  <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> DBA_JOBS_RUNNING; <span class="comment">--查看那个作业在那个队列上的进度</span></span><br></pre></td></tr></table></figure></code></pre><h2 id="检查物化视图的状态"><a class="markdownIt-Anchor" href="#检查物化视图的状态"></a> 检查物化视图的状态</h2><p>oracle提供了3个视图用来检查物化视图的状态.</p><ul><li>DBA_MVEIWS</li><li>ALL_MVIEWS</li><li>USER_MVIEWS</li></ul><h5 id="检查物化视图是新的还是旧的"><a class="markdownIt-Anchor" href="#检查物化视图是新的还是旧的"></a> 检查物化视图是新的还是旧的</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> MVIEW_NAME, STALENESS, LAST_REFRESH_TYPE, COMPILE_STATE </span><br><span class="line"><span class="keyword">FROM</span> USER_MVIEWS <span class="keyword">ORDER</span> <span class="keyword">BY</span> MVIEW_NAME;</span><br><span class="line"></span><br><span class="line">MVIEW_NAME            STALENESS      LAST_REF       COMPILE_STATE</span><br><span class="line"><span class="comment">----------            ---------      --------       -------------</span></span><br><span class="line">CUST_MTH_SALES_MV     NEEDS_COMPILE  FAST           NEEDS_COMPILE</span><br><span class="line">PROD_YR_SALES_MV      FRESH          FAST           VALID</span><br></pre></td></tr></table></figure><p>如果 <code>COMPILE_STATE</code> 是 <code>NEEDS_COMPILE</code> ,那么这条信息的其他列都不准确。</p><ul><li>要重新将物化视图编译，执行下面语句:</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> MATERIALIZED <span class="keyword">VIEW</span> [materialized_view_name] COMPILE;</span><br></pre></td></tr></table></figure><h5 id="可以使用下面的几个视图来检查分区是否新鲜"><a class="markdownIt-Anchor" href="#可以使用下面的几个视图来检查分区是否新鲜"></a> 可以使用下面的几个视图来检查分区是否新鲜</h5><ul><li>USER_MVIEWS 确定物化视图的分区更改跟踪PCT信息</li><li>USER_MVIEW_DETAIL_RELATIONS 显示明细表的分区信息。</li><li>USER_MVIEW_DETAIL_PARTITION 确定那些分区是新的。</li><li>USER_MVIEW_DETAIL_SUBPARTITION 确定那些子分区是新的。</li></ul><p>下图展示了一个范围列表分区表和一个基于它的物化视图。</p><ul><li>分区 P1，P2,P3,P4</li><li>子分区 SP1，SP2，SP3<br /><img src="https://github-hexo-picturebed.s3.ap-southeast-1.amazonaws.com/story/Oracle/Refreshing+Materialized+View/DeterMining+PCT+Freshness.png" alt="enter description here" /></li></ul><p>下面是一些用上面的视图来确认MV的是否新鲜</p><h5 id="通过user_mviews-查询视图的pct信息"><a class="markdownIt-Anchor" href="#通过user_mviews-查询视图的pct信息"></a> 通过<code>USER_MVIEWS</code> 查询视图的PCT信息。</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> MVIEW_NAME, NUM_PCT_TABLES, NUM_FRESH_PCT_REGIONS,</span><br><span class="line">   NUM_STALE_PCT_REGIONS</span><br><span class="line"><span class="keyword">FROM</span> USER_MVIEWS</span><br><span class="line"><span class="keyword">WHERE</span> MVIEW_NAME <span class="operator">=</span> MV1;</span><br><span class="line"></span><br><span class="line">MVIEW_NAME NUM_PCT_TABLES NUM_FRESH_PCT_REGIONS NUM_STALE_PCT_REGIONS</span><br><span class="line"><span class="comment">---------- -------------- --------------------- ---------------------</span></span><br><span class="line">       MV1              <span class="number">1</span>                     <span class="number">9</span>                     <span class="number">3</span></span><br></pre></td></tr></table></figure><h5 id="通过-user_mview_detail_relations-查询视图的pct信息"><a class="markdownIt-Anchor" href="#通过-user_mview_detail_relations-查询视图的pct信息"></a> 通过 <code>USER_MVIEW_DETAIL_RELATIONS</code> 查询视图的PCT信息</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> MVIEW_NAME, DETAILOBJ_NAME, DETAILOBJ_PCT,</span><br><span class="line">   NUM_FRESH_PCT_PARTITIONS, NUM_STALE_PCT_PARTITIONS</span><br><span class="line"><span class="keyword">FROM</span> USER_MVIEW_DETAIL_RELATIONS</span><br><span class="line"><span class="keyword">WHERE</span> MVIEW_NAME <span class="operator">=</span> MV1;</span><br><span class="line"></span><br><span class="line">MVIEW_NAME  DETAILOBJ_NAME  DETAIL_OBJ_PCT  NUM_FRESH_PCT_PARTITIONS  NUM_STALE_PCT_PARTITIONS</span><br><span class="line"><span class="comment">----------  --------------  --------------  ------------------------  ------------------------</span></span><br><span class="line">        MV1             T1               Y                         <span class="number">3</span>                         <span class="number">1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="通过-user_mview_detail_partition-查询视图的pct信息"><a class="markdownIt-Anchor" href="#通过-user_mview_detail_partition-查询视图的pct信息"></a> 通过 <code>USER_MVIEW_DETAIL_PARTITION</code> 查询视图的PCT信息</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> MVIEW_NAME,DETAILOBJ_NAME,DETAIL_PARTITION_NAME,</span><br><span class="line">   DETAIL_PARTITION_POSITION,FRESHNESS</span><br><span class="line"><span class="keyword">FROM</span> USER_MVIEW_DETAIL_PARTITION</span><br><span class="line"><span class="keyword">WHERE</span> MVIEW_NAME <span class="operator">=</span> MV1;</span><br><span class="line"></span><br><span class="line">MVIEW_NAME  DETAILOBJ_NAME  DETAIL_PARTITION_NAME  DETAIL_PARTITION_POSITION  FRESHNESS</span><br><span class="line"><span class="comment">----------  --------------  ---------------------  -------------------------  ---------</span></span><br><span class="line">       MV1               T1                    P1                          <span class="number">1</span>      FRESH</span><br><span class="line">       MV1               T1                    P2                          <span class="number">2</span>      FRESH</span><br><span class="line">       MV1               T1                    P3                          <span class="number">3</span>      STALE</span><br><span class="line">       MV1               T1                    P4                          <span class="number">4</span>      FRESH</span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="通过-user_mview_detail_subpartition-查询视图的pct信息"><a class="markdownIt-Anchor" href="#通过-user_mview_detail_subpartition-查询视图的pct信息"></a> 通过 <code>USER_MVIEW_DETAIL_SUBPARTITION</code> 查询视图的PCT信息</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> MVIEW_NAME,DETAILOBJ_NAME,DETAIL_PARTITION_NAME, DETAIL_SUBPARTITION_NAME,</span><br><span class="line">    DETAIL_SUBPARTITION_POSITION,FRESHNESS</span><br><span class="line"><span class="keyword">FROM</span> USER_MVIEW_DETAIL_SUBPARTITION</span><br><span class="line"><span class="keyword">WHERE</span> MVIEW_NAME <span class="operator">=</span> MV1;</span><br><span class="line"></span><br><span class="line">MVIEW_NAME DETAILOBJ DETAIL_PARTITION DETAIL_SUBPARTITION_NAME DETAIL_SUBPARTITION_POS FRESHNESS</span><br><span class="line"><span class="comment">---------- --------- ---------------- ------------------------ ----------------------- ---------</span></span><br><span class="line">       MV1        T1               P1                      SP1                       <span class="number">1</span>     FRESH</span><br><span class="line">       MV1        T1               P1                      SP2                       <span class="number">1</span>     FRESH</span><br><span class="line">       MV1        T1               P1                      SP3                       <span class="number">1</span>     FRESH</span><br><span class="line">       MV1        T1               P2                      SP1                       <span class="number">1</span>     FRESH</span><br><span class="line">       MV1        T1               P2                      SP2                       <span class="number">1</span>     FRESH</span><br><span class="line">       MV1        T1               P2                      SP3                       <span class="number">1</span>     FRESH</span><br><span class="line">       MV1        T1               P3                      SP1                       <span class="number">1</span>     STALE</span><br><span class="line">       MV1        T1               P3                      SP2                       <span class="number">1</span>     STALE</span><br><span class="line">       MV1        T1               P3                      SP3                       <span class="number">1</span>     STALE</span><br><span class="line">       MV1        T1               P4                      SP1                       <span class="number">1</span>     FRESH</span><br><span class="line">       MV1        T1               P4                      SP2                       <span class="number">1</span>     FRESH</span><br><span class="line">       MV1        T1               P4                      SP3                       <span class="number">1</span>     FRESH</span><br><span class="line"></span><br></pre></td></tr></table></figure></font>]]></content>
    
    
      
      
    <summary type="html">&lt;font face=&quot;黑体&quot;&gt;
&lt;h1 id=&quot;refer-to&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#refer-to&quot;&gt;&lt;/a&gt; refer to&lt;/h1&gt;
&lt;p&gt;Oracle 官方文档 Url : &lt;a href=&quot;https://do</summary>
      
    
    
    
    
    <category term="Oracle" scheme="http://example.com/tags/Oracle/"/>
    
  </entry>
  
  <entry>
    <title>Spark Evn Deployment(Spark 环境部署)</title>
    <link href="http://example.com/2022/04/13/Spark-Evn-Deployment-Spark-%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/"/>
    <id>http://example.com/2022/04/13/Spark-Evn-Deployment-Spark-%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/</id>
    <published>2022-04-13T11:29:03.000Z</published>
    <updated>2022-04-13T11:30:38.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="spark-on-yarn"><a class="markdownIt-Anchor" href="#spark-on-yarn"></a> Spark On Yarn</h1><h3 id="安装环境"><a class="markdownIt-Anchor" href="#安装环境"></a> 安装环境</h3><ul><li>yarn: hadoop-2.6.1</li><li>hive:apache-hive-1.2.2-bin</li><li>spark:spark-2.0.2-bin-hadoop2.6</li><li>scala:scala-2.11.8</li></ul><h3 id="yarn-集群"><a class="markdownIt-Anchor" href="#yarn-集群"></a> Yarn 集群</h3><ul><li>master:192.168.146.129</li><li>slave1:192.168.146.130</li><li>slave2:192.168.146.131</li><li>SSH信任已经配置成功</li></ul><h3 id="获取安装包"><a class="markdownIt-Anchor" href="#获取安装包"></a> 获取安装包</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://mirror.bit.edu.cn/apache/spark/spark-2.0.2/spark-2.0.2-bin-hadoop2.6.tgz</span><br></pre></td></tr></table></figure><p>或者自己上传</p><h4 id="解压"><a class="markdownIt-Anchor" href="#解压"></a> 解压</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@master src]# ll *.tgz       </span><br><span class="line">-rw-r--r--. 1 root root  28678231 Jun  8 19:40 scala-2.11.8.tgz</span><br><span class="line">-rw-r--r--. 1 root root 185040619 Jun  8 19:41 spark-2.0.2-bin-hadoop2.6.tgz</span><br><span class="line">[root@master src]# pwd</span><br><span class="line">/usr/local/src</span><br><span class="line">[root@master src]# tar -xvzf spark-2.0.2-bin-hadoop2.6.tgz </span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="修改配置信息"><a class="markdownIt-Anchor" href="#修改配置信息"></a> 修改配置信息</h3><h4 id="编辑-spark-envsh"><a class="markdownIt-Anchor" href="#编辑-spark-envsh"></a> 编辑 <a href="http://Spark-env.sh">Spark-env.sh</a></h4><p>添加</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">export SCALA_HOME=/usr/local/src/scala-2.11.8</span><br><span class="line">export JAVA_HOME=/usr/local/src/jdk1.7.0_67</span><br><span class="line">export HADOOP_HOME=/usr/local/src/hadoop-2.6.1</span><br><span class="line">export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop</span><br><span class="line">export SPARK_LOCAL_DIRS=/usr/local/src/spark-2.0.2-bin-hadoop2.6</span><br><span class="line">export SPARK_MASTER_IP=master</span><br><span class="line">export SPARK_DRIVER_MEMORY=2G</span><br></pre></td></tr></table></figure><h4 id="编辑-slaves"><a class="markdownIt-Anchor" href="#编辑-slaves"></a> 编辑 slaves</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master conf]# cp slaves.template slaves</span><br><span class="line">[root@master conf]# vim slaves</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">A Spark Worker will be started on each of the machines listed below.</span></span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="将配置好的spark安装目录分发到slave12-节点上"><a class="markdownIt-Anchor" href="#将配置好的spark安装目录分发到slave12-节点上"></a> 将配置好的spark安装目录，分发到slave1/2 节点上。</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master bin]# scp -r  spark-2.0.2-bin-hadoop2.6  root@slave1:/usr/local/src/</span><br><span class="line">[root@master bin]# scp -r  spark-2.0.2-bin-hadoop2.6  root@slave2:/usr/local/src/</span><br></pre></td></tr></table></figure><h3 id="启动spark进程"><a class="markdownIt-Anchor" href="#启动spark进程"></a> 启动spark进程</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@master spark-2.0.2-bin-hadoop2.6]# ./sbin/start-all.sh </span><br><span class="line">starting org.apache.spark.deploy.master.Master, logging to /usr/local/src/spark-2.0.2-bin-hadoop2.6/logs/spark-root-org.apache.spark.deploy.master.Master-1-master.out</span><br><span class="line">slave2: starting org.apache.spark.deploy.worker.Worker, logging to /usr/local/src/spark-2.0.2-bin-hadoop2.6/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-slave2.out</span><br><span class="line">slave1: starting org.apache.spark.deploy.worker.Worker, logging to /usr/local/src/spark-2.0.2-bin-hadoop2.6/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-slave1.out</span><br><span class="line">[root@master spark-2.0.2-bin-hadoop2.6]# jps</span><br><span class="line">10989 Jps</span><br><span class="line">10920 Master</span><br><span class="line">2694 SecondaryNameNode</span><br><span class="line">2551 NameNode</span><br><span class="line">2843 ResourceManager</span><br></pre></td></tr></table></figure><h3 id="启动spark-shell"><a class="markdownIt-Anchor" href="#启动spark-shell"></a> 启动spark-shell</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@master spark-2.0.2-bin-hadoop2.6]# ./bin/spark-shell </span><br><span class="line">Setting default log level to &quot;WARN&quot;.</span><br><span class="line">To adjust logging level use sc.setLogLevel(newLevel).</span><br><span class="line">18/06/26 00:57:35 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">18/06/26 00:57:41 WARN spark.SparkContext: Use an existing SparkContext, some configuration may not take effect.</span><br><span class="line">Spark context Web UI available at http://192.168.146.129:4040</span><br><span class="line">Spark context available as &#x27;sc&#x27; (master = local[*], app id = local-1529999859799).</span><br><span class="line">Spark session available as &#x27;spark&#x27;.</span><br><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  &#x27;_/</span><br><span class="line">   /___/ .__/\_,_/_/ /_/\_\   version 2.0.2</span><br><span class="line">      /_/</span><br><span class="line">         </span><br><span class="line">Using Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_67)</span><br><span class="line">Type in expressions to have them evaluated.</span><br><span class="line">Type :help for more information.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">scala&gt; </span></span><br></pre></td></tr></table></figure><h3 id="验证spark"><a class="markdownIt-Anchor" href="#验证spark"></a> 验证spark</h3><ul><li>本地模式：<br /><code>– ]# ./bin/run-example SparkPi 10 --master local[2]</code></li><li>集群模式 Spark Standalone：<br /><code>– ]# ./bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://master:7077 examples/jars/spark-examples_2.11-2.0.2.jar 100</code></li><li>集群模式 Spark on Yarn集群上yarn-cluster模式：<br /><code>– ]# ./bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn-cluster examples/jars/spark-examples_2.11-2.0.2.jar 10</code></li></ul><h4 id="验证spark-on-yarn"><a class="markdownIt-Anchor" href="#验证spark-on-yarn"></a> 验证spark on yarn 。</h4><p><img src="https://github-hexo-picturebed.s3.ap-southeast-1.amazonaws.com/story/Spark-Installation-Configuration/SparkOnYarn.png" alt="Spark on yarn" /></p><p><img src="https://github-hexo-picturebed.s3.ap-southeast-1.amazonaws.com/story/Spark-Installation-Configuration/InfoOfMonitorPage.png" alt="监控页面信息" /></p><h4 id="配置spark-connect-hive"><a class="markdownIt-Anchor" href="#配置spark-connect-hive"></a> 配置spark connect hive</h4><p>因为需要在spark里调用sparksql。所以需要spark 访问hive数据。</p><ul><li>需要将hive-site.xml 拷贝到spark 的conf 目录下。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /usr/local/src/apache-hive-1.2.2-bin/conf/hive-site.xml /usr/local/src/spark-2.0.2-bin-hadoop2.6/conf/</span><br></pre></td></tr></table></figure><ul><li>将对应的mysql-connector-java-5.1.44-bin.jar 放到$SPARK_HOME/jars/目录下。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /usr/local/src/mysql-connector-java-5.1.41/mysql-connector-java-5.1.41-bin.jar /usr/local/src/spark-2.0.2-bin-hadoop2.6/jars/ </span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;spark-on-yarn&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#spark-on-yarn&quot;&gt;&lt;/a&gt; Spark On Yarn&lt;/h1&gt;
&lt;h3 id=&quot;安装环境&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot;</summary>
      
    
    
    
    
    <category term="spark" scheme="http://example.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>HDFS Architecture(HDFS 架构)</title>
    <link href="http://example.com/2022/04/13/HDFS-Architecture-HDFS-%E6%9E%B6%E6%9E%84/"/>
    <id>http://example.com/2022/04/13/HDFS-Architecture-HDFS-%E6%9E%B6%E6%9E%84/</id>
    <published>2022-04-13T11:22:06.000Z</published>
    <updated>2022-04-13T11:23:56.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://github-hexo-picturebed.s3.ap-southeast-1.amazonaws.com/story/HDFS-Architecture/HDFSArchitecture.png" alt="HDFS Architecture" /></p><ul><li><p>HDFS有一个主/从架构，一个HDFS集群由一个单一的NameNode，它是管理文件系统命名空间的主服务器，并管理客户对文件的访问。NameNode执行文件系统命名空间操作，如打开，关闭和重命名文件和目录。它还确定块到DataNode的映射关系。</p></li><li><p>此外，还有许多的DataNode(通常每个节点一个)，它们管理所在的节点的数据存储。DataNodes负责处理来自Clients的读写请求。同时再NameNode的指令下执行Block的创建，删除，复制。</p></li><li><p>HDFS 公开一个命名空间，允许用户数据存储再文件中。再内部文件被分割成一个或者多个数据块，这些数据块存储再DataNode集群中。</p></li><li><p>典型的HDFS集群，会有一个专用的机器来运行NameNode，其他机器都运行一个DataNode实例。</p></li></ul><p>Note: 集群中单个NameNode的存在极大地简化了系统的架构，NameNode是所有HDFS元数据的仲裁器和存储库。用户的数据是永远不会通过NameNode。</p><h3 id="文件系统命名空间"><a class="markdownIt-Anchor" href="#文件系统命名空间"></a> 文件系统命名空间</h3><ul><li>HDFS的文件系统类似于传统的分层结构，用户同样可以创建目录并且在目录下创建文件、删除文件，移动文件或者重命名文件. HDFS2.6.5目前还不支持对用户进行分配额度或者访问权限，以及文件间的软硬链接。未来可能会有这种功能。</li><li>NameNode维护文件系统命名空间，对其的任何更改都会进行记录。</li><li>可以指定一个文件的副本数量。一般为3份。 文件的拷贝数称为文件的复制因子。可以由参数指定。</li></ul><h1 id="数据复制data-replication"><a class="markdownIt-Anchor" href="#数据复制data-replication"></a> 数据复制(Data Replication)</h1><p>HDFS在集群中存储大文件，将每个文件存储为快序列。一个文件的所有的块除了最后一个block 其他的block 都是一样的大小。<br />每个文件的复制因子(备份) 的数量是可以指定的。</p><p><img src="https://github-hexo-picturebed.s3.ap-southeast-1.amazonaws.com/story/HDFS-Architecture/HDFSDataReplication.png" alt="Data Replication" /></p><h2 id="副本放置策略"><a class="markdownIt-Anchor" href="#副本放置策略"></a> 副本放置策略</h2><p>HDFS的数据复制对提高其可靠性和性能至关重要。</p><h3 id="机架感知策略"><a class="markdownIt-Anchor" href="#机架感知策略"></a> 机架感知策略</h3><ul><li>比如副本数量指定为3时。 HDFS的放置策略是将一个副本放在本地机架的一个node上，另一个副本放在本地机架的另一个node上。最后一个副本放在另一个机架的另一个节点上。</li><li>这种策略减少了机架间的写流量，提高写性能。机架间的故障概率远小于节点故障的概率。这个策略，文件的副本就不会均匀分布再各个机架上。三分之一的副本再一个节点上，三分之二的副本再一个架子上，另外三分之一均匀分布在剩下的架子上。</li><li>这种策略改进了写性能，而不影响数据可靠性或读性能。</li></ul><h2 id="副本选择"><a class="markdownIt-Anchor" href="#副本选择"></a> 副本选择</h2><ul><li>为了最小化带宽消耗和读取延迟，在一个读取请求过来的时候，如果在读取节点所在机架上存在一个请求的副本，那么这个副本更适合提供读取请求。</li></ul><h2 id="安全模式"><a class="markdownIt-Anchor" href="#安全模式"></a> 安全模式</h2><ul><li>在集群启动的时候，NameNode会进入一种Safemode(安全模式)的特殊状态。这时候是不会发生数据库复制的。只有当NameNode接收到DataNodes的心跳和block report后。 Block报告包含DataNodes管理的所有的数据块的列表。NameNode会检查数据块的最小复制数、在检查数据快复制百分比之后。退出安全模式。</li><li>这时候确定仍然少于指定的副本数量。NameNode 会将这些块按照对应的策略复制到其他的DataNode。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://github-hexo-picturebed.s3.ap-southeast-1.amazonaws.com/story/HDFS-Architecture/HDFSArchitecture.png&quot; alt=&quot;HDFS Architec</summary>
      
    
    
    
    
    <category term="Hadoop" scheme="http://example.com/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>blog test</title>
    <link href="http://example.com/2022/04/13/blog-test/"/>
    <id>http://example.com/2022/04/13/blog-test/</id>
    <published>2022-04-13T06:09:24.000Z</published>
    <updated>2022-04-13T06:09:26.000Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://example.com/2022/04/12/hello-world/"/>
    <id>http://example.com/2022/04/12/hello-world/</id>
    <published>2022-04-12T10:03:52.260Z</published>
    <updated>2022-04-12T10:03:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="quick-start"><a class="markdownIt-Anchor" href="#quick-start"></a> Quick Start</h2><h3 id="create-a-new-post"><a class="markdownIt-Anchor" href="#create-a-new-post"></a> Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server"><a class="markdownIt-Anchor" href="#run-server"></a> Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files"><a class="markdownIt-Anchor" href="#generate-static-files"></a> Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites"><a class="markdownIt-Anchor" href="#deploy-to-remote-sites"></a> Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
