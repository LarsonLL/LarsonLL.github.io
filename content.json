{"meta":{"title":"Hexo","subtitle":"","description":"AA","author":"John Doe","url":"http://example.com","root":"/"},"pages":[{"title":"书单","date":"2009-04-22T19:24:48.000Z","updated":"2022-04-13T14:18:42.000Z","comments":false,"path":"books/index.html","permalink":"http://example.com/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2009-04-22T19:24:48.000Z","updated":"2022-04-13T14:18:42.000Z","comments":true,"path":"links/index.html","permalink":"http://example.com/links/index.html","excerpt":"","text":""}],"posts":[{"title":"Refresh Materialized View","slug":"Refresh-Materialized-View","date":"2022-04-13T11:36:38.000Z","updated":"2022-04-13T11:38:10.000Z","comments":true,"path":"2022/04/13/Refresh-Materialized-View/","link":"","permalink":"http://example.com/2022/04/13/Refresh-Materialized-View/","excerpt":"","text":"refer to Oracle 官方文档 Url : https://docs.oracle.com/cd/E11882_01/server.112/e25554/refresh.htm#DWHSG03003 概述 在创建 materialized view 的时候可以指定两种刷新方式 ON COMMIT 在这种机制下，Materialized view 在每次commit 的时候都会自动 refresh。 ON DEMAND 在这中case下，Materialized view 只能通过call DBMS_MVIEW 这个package中的procedure才能进行refresh DBMS_MVIEW 提供3种刷新方式 DBMS_MVIEW.REFRESH # 刷新一个或者多个物化视图 DBMS_MVIEW.REFRESH_ALL_MVIEWS # 刷新所有的物化视图 DBMS_MVIEW.REFRESH_DEPENDENT # 刷新所有依赖于指定的主表、物化视图（可以是多个）的物化视图 Note: 由于刷新物化视图操作需要临时空间来重建索引，并且可能需要额外的空间来执行刷新操作本身，所以不需要频繁的进行刷新操作。因此如果没有及时刷新物化视图的话，需要考虑查询重写的问题。 可以通过 ALTER SYSTEM SET QUERY_REWRITE_ENABLED = FALSE or TRUE 来禁用或者启用查询重写操作。 Oracle 版本 10 以下 默认为fales ， 10 以上 为TRUE If you anticipate performing insert, update or delete operations on tables referenced by a materialized view concurrently with the refresh of that materialized view, and that materialized view includes joins and aggregation, Oracle recommends you use ON COMMIT fast refresh rather than ON DEMAND fast refresh.(如果预计在物化视图刷新的同时对物化视图引用的表执行插入，更新或删除操作，并且该物化视图包含连接和聚合，Oracle建议您使用ON COMMIT快速刷新而不是ON DEMAND快速刷新。) Refresh method (4种) Complete Refresh build immediate 在物化视图第一次创建的时候会发生完全刷新，除非创建的物化视图引用的表还没有被创建. build deferred 创建的物化视图，第一时间是不会进行完全刷新，但必须在第一次使用之前进行一次完整的刷新. 刷新过程需要读取细节表，计算物化视图结果，非常耗时，尤其是当需要读取大量数据时。 Fast Refresh 对比上面的完整刷新，快速刷新物化视图不需要重新计算整个物化视图，而是将更改现有的数据，所以会比较快 Partition Change Tracking (PCT) Refresh 当物化视图引用的表有分区操作的时候，只能使用快速刷新(Fast Refresh) ,但是要满足PCT 的所有条件才允许基于PC的刷新。 -对于没有分区的表，如果使用Fast Refresh (method =&gt; ‘F’),Oracle在执行之前会尝试基于log的快速刷新。 类似的当使用Force方法刷新的时候，Oracle 会按如下顺序选择Refresh方式: log-based fast refresh , PCT refresh , complete 当然你也可以指定PCT刷新方式（method =&gt; ‘P’） ON COMMIT Refresh 使用这种方法自动刷新物化视图，当事物更新了一个物化视图引用的表时，这些changes会自动刷新到对应的物化视图上。 好处是 不需要定时刷新物化视图 缺点 commit 需要的时间比较长。不过如果再数据仓库中应该不是问题，因为不太可能并发进程，所以再OLTP中要避免这种MV。 Manual Refresh Using The DBMS_MVIEW package 刷新物化视图时，可以指定4中方法之一，入下图所示 Refresh Option Parameter Description COMPLETE C 通过重新计算物化视图定义的查询来刷新 FAST F 通过增量地对物化视图应用更改来刷新，对于本地物化视图，它选择由优化器估计的最新方法。所考虑的刷新方法是基于日志的快速和FAST_PCT。 FAST_PCT P 通过重新计算在引用的明细表中受到更改的分区影响的物化视图中的行来进行刷新。 FORCE F&amp;？ 先尝试快速刷新，如果不符合快速刷新条件，就会进行完全刷新。优化器选择的刷新基于日子的FAST ，FAST_PCT 和 COMPLETE Refresh procedure (常用的3种) 调用DBMS_MVIEW.REFRESH刷新Materialized View 如果多个物化视图一起刷新需要用逗号分割。(list&amp;tab) 刷新方法: F-Fast , P-Fast_PCT , ? - Force , C-Complete (Method) 使用回滚段 (rollback_seg) 默认为 NULL 在错误之后是否进行刷新(TRUE or FALSE)。True: 那么需要将 number_of_failure 设置一个失败以后刷新的次数，类似于重新请求。FALSE: 默认Refresh 在遇到第一个错误的时候就会停止，并且列表剩余的物化视图不会刷新。 （refresh_after_errors） 默认为FALSE 下面的4个参数，用来进行 replication 过程的时候，一般再数据仓库的刷新时候 依次设置为 FALSE,0,0,0 Atomic refresh (TRUE or FALSE) atomic_refresh 默认为TRUE TRUE: 所有的刷新操作在一个事物中完成. FALSE: 在单独的事务中刷新每个指定的物化视图。 For exampl fast refresh MV : cal_month_sales_mv 1DBMS_MVIEW.REFRESH(&#x27;CAL_MONTH_SALES_MV&#x27;, &#x27;F&#x27;, &#x27;&#x27;, TRUE, FALSE, 0,0,0, FALSE); 多个物化视图刷新:CAL_MONTH_SALES_MV 完全刷新 FWEEK_PSCAT_SALES_MV 快速刷新 12DBMS_MVIEW.REFRESH(&#x27;CAL_MONTH_SALES_MV, FWEEK_PSCAT_SALES_MV&#x27;, &#x27;CF&#x27;, &#x27;&#x27;, TRUE, FALSE, 0,0,0, FALSE); Note: 如果未指定refresh方法，则使用物化视图定义中指定的默认刷新方法。 调用DMBS_MVIEW.REFRESH_ALL_MVIEWS刷新所有的Materialized View 这个Procedure 会刷新所有的物化视图，如果其中有未成功刷新的物化视图，会返回失败的次数。 Parameter 失败数量，这是一个输出的变量OUT () number_of_failures 刷新方法，F-Fast, P-Fast_PCT, ?-Force, C-Complete 在错误之后是否进行刷新(TRUE or FALSE)。True: 那么需要将 number_of_failure 设置一个失败以后刷新的次数，类似于重新请求。FALSE: 默认Refresh 在遇到第一个错误的时候就会停止，并且列表剩余的物化视图不会刷新。 （refresh_after_errors） 默认为FALSE， Atomic refresh (TRUE or FALSE) atomic_refresh 默认为TRUE TRUE: 所有的刷新操作在一个事物中完成. FALSE: 在单独的事务中刷新每个指定的物化视图。 For Example 1DBMS_MVIEW.REFRESH_ALL_MVIEWS(failures,&#x27;C&#x27;,&#x27;&#x27;, TRUE, FALSE); 调用 DMBS_MVIEW.REFRESH_DEPENDENT 刷新那些依赖于特定表或者表列表的物化视图。 Parameter 失败数量，这是一个输出的变量OUT (number_of_failures) 相关的表 (list&amp;tab) 刷新方法，F-Fast, P-Fast_PCT, ?-Force, C-Complete (Method) 使用回滚段 (rollback_seg) 默认为 NULL 在错误之后是否进行刷新(TRUE or FALSE) 同上 Atomic refresh (TRUE or FALSE) atomic_refresh 默认为TRUE 同上 是否嵌套 nested 默认为 FALSE 。 如果是TRUE 会根据依赖项顺序刷新指定表集的所有相关物化视图，以确保物化视图相对于底层基表而言是新鲜的。 For Example 1234567891011 DBMS_MVIEW.REFRESH_DEPENDENT(failures, &#x27;CUSTOMERS&#x27;, &#x27;C&#x27;, &#x27;&#x27;, FALSE, FALSE ); ``` # 附录## 如何确定物化视图是否可以进行快速刷新 - `DBMS_ADVISOR.TUNE_MVIEW` ## 监控执行的刷新 ```sql SELECT * FROM V$SESSION_LONGOPS; SELECT * FROM DBA_JOBS_RUNNING; --查看那个作业在那个队列上的进度 检查物化视图的状态 oracle提供了3个视图用来检查物化视图的状态. DBA_MVEIWS ALL_MVIEWS USER_MVIEWS 检查物化视图是新的还是旧的 1234567SELECT MVIEW_NAME, STALENESS, LAST_REFRESH_TYPE, COMPILE_STATE FROM USER_MVIEWS ORDER BY MVIEW_NAME;MVIEW_NAME STALENESS LAST_REF COMPILE_STATE---------- --------- -------- -------------CUST_MTH_SALES_MV NEEDS_COMPILE FAST NEEDS_COMPILEPROD_YR_SALES_MV FRESH FAST VALID 如果 COMPILE_STATE 是 NEEDS_COMPILE ,那么这条信息的其他列都不准确。 要重新将物化视图编译，执行下面语句: 1ALTER MATERIALIZED VIEW [materialized_view_name] COMPILE; 可以使用下面的几个视图来检查分区是否新鲜 USER_MVIEWS 确定物化视图的分区更改跟踪PCT信息 USER_MVIEW_DETAIL_RELATIONS 显示明细表的分区信息。 USER_MVIEW_DETAIL_PARTITION 确定那些分区是新的。 USER_MVIEW_DETAIL_SUBPARTITION 确定那些子分区是新的。 下图展示了一个范围列表分区表和一个基于它的物化视图。 分区 P1，P2,P3,P4 子分区 SP1，SP2，SP3 下面是一些用上面的视图来确认MV的是否新鲜 通过USER_MVIEWS 查询视图的PCT信息。 12345678SELECT MVIEW_NAME, NUM_PCT_TABLES, NUM_FRESH_PCT_REGIONS, NUM_STALE_PCT_REGIONSFROM USER_MVIEWSWHERE MVIEW_NAME = MV1;MVIEW_NAME NUM_PCT_TABLES NUM_FRESH_PCT_REGIONS NUM_STALE_PCT_REGIONS---------- -------------- --------------------- --------------------- MV1 1 9 3 通过 USER_MVIEW_DETAIL_RELATIONS 查询视图的PCT信息 123456789SELECT MVIEW_NAME, DETAILOBJ_NAME, DETAILOBJ_PCT, NUM_FRESH_PCT_PARTITIONS, NUM_STALE_PCT_PARTITIONSFROM USER_MVIEW_DETAIL_RELATIONSWHERE MVIEW_NAME = MV1;MVIEW_NAME DETAILOBJ_NAME DETAIL_OBJ_PCT NUM_FRESH_PCT_PARTITIONS NUM_STALE_PCT_PARTITIONS---------- -------------- -------------- ------------------------ ------------------------ MV1 T1 Y 3 1 通过 USER_MVIEW_DETAIL_PARTITION 查询视图的PCT信息 123456789101112SELECT MVIEW_NAME,DETAILOBJ_NAME,DETAIL_PARTITION_NAME, DETAIL_PARTITION_POSITION,FRESHNESSFROM USER_MVIEW_DETAIL_PARTITIONWHERE MVIEW_NAME = MV1;MVIEW_NAME DETAILOBJ_NAME DETAIL_PARTITION_NAME DETAIL_PARTITION_POSITION FRESHNESS---------- -------------- --------------------- ------------------------- --------- MV1 T1 P1 1 FRESH MV1 T1 P2 2 FRESH MV1 T1 P3 3 STALE MV1 T1 P4 4 FRESH 通过 USER_MVIEW_DETAIL_SUBPARTITION 查询视图的PCT信息 1234567891011121314151617181920SELECT MVIEW_NAME,DETAILOBJ_NAME,DETAIL_PARTITION_NAME, DETAIL_SUBPARTITION_NAME, DETAIL_SUBPARTITION_POSITION,FRESHNESSFROM USER_MVIEW_DETAIL_SUBPARTITIONWHERE MVIEW_NAME = MV1;MVIEW_NAME DETAILOBJ DETAIL_PARTITION DETAIL_SUBPARTITION_NAME DETAIL_SUBPARTITION_POS FRESHNESS---------- --------- ---------------- ------------------------ ----------------------- --------- MV1 T1 P1 SP1 1 FRESH MV1 T1 P1 SP2 1 FRESH MV1 T1 P1 SP3 1 FRESH MV1 T1 P2 SP1 1 FRESH MV1 T1 P2 SP2 1 FRESH MV1 T1 P2 SP3 1 FRESH MV1 T1 P3 SP1 1 STALE MV1 T1 P3 SP2 1 STALE MV1 T1 P3 SP3 1 STALE MV1 T1 P4 SP1 1 FRESH MV1 T1 P4 SP2 1 FRESH MV1 T1 P4 SP3 1 FRESH","categories":[],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"http://example.com/tags/Oracle/"}]},{"title":"Spark Evn Deployment(Spark 环境部署)","slug":"Spark-Evn-Deployment-Spark-环境部署","date":"2022-04-13T11:29:03.000Z","updated":"2022-04-13T11:30:38.000Z","comments":true,"path":"2022/04/13/Spark-Evn-Deployment-Spark-环境部署/","link":"","permalink":"http://example.com/2022/04/13/Spark-Evn-Deployment-Spark-%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/","excerpt":"","text":"Spark On Yarn 安装环境 yarn: hadoop-2.6.1 hive:apache-hive-1.2.2-bin spark:spark-2.0.2-bin-hadoop2.6 scala:scala-2.11.8 Yarn 集群 master:192.168.146.129 slave1:192.168.146.130 slave2:192.168.146.131 SSH信任已经配置成功 获取安装包 1wget http://mirror.bit.edu.cn/apache/spark/spark-2.0.2/spark-2.0.2-bin-hadoop2.6.tgz 或者自己上传 解压 1234567[root@master src]# ll *.tgz -rw-r--r--. 1 root root 28678231 Jun 8 19:40 scala-2.11.8.tgz-rw-r--r--. 1 root root 185040619 Jun 8 19:41 spark-2.0.2-bin-hadoop2.6.tgz[root@master src]# pwd/usr/local/src[root@master src]# tar -xvzf spark-2.0.2-bin-hadoop2.6.tgz 修改配置信息 编辑 Spark-env.sh 添加 1234567export SCALA_HOME=/usr/local/src/scala-2.11.8export JAVA_HOME=/usr/local/src/jdk1.7.0_67export HADOOP_HOME=/usr/local/src/hadoop-2.6.1export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoopexport SPARK_LOCAL_DIRS=/usr/local/src/spark-2.0.2-bin-hadoop2.6export SPARK_MASTER_IP=masterexport SPARK_DRIVER_MEMORY=2G 编辑 slaves 12345[root@master conf]# cp slaves.template slaves[root@master conf]# vim slaves# A Spark Worker will be started on each of the machines listed below.slave1slave2 将配置好的spark安装目录，分发到slave1/2 节点上。 12[root@master bin]# scp -r spark-2.0.2-bin-hadoop2.6 root@slave1:/usr/local/src/[root@master bin]# scp -r spark-2.0.2-bin-hadoop2.6 root@slave2:/usr/local/src/ 启动spark进程 12345678910[root@master spark-2.0.2-bin-hadoop2.6]# ./sbin/start-all.sh starting org.apache.spark.deploy.master.Master, logging to /usr/local/src/spark-2.0.2-bin-hadoop2.6/logs/spark-root-org.apache.spark.deploy.master.Master-1-master.outslave2: starting org.apache.spark.deploy.worker.Worker, logging to /usr/local/src/spark-2.0.2-bin-hadoop2.6/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-slave2.outslave1: starting org.apache.spark.deploy.worker.Worker, logging to /usr/local/src/spark-2.0.2-bin-hadoop2.6/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-slave1.out[root@master spark-2.0.2-bin-hadoop2.6]# jps10989 Jps10920 Master2694 SecondaryNameNode2551 NameNode2843 ResourceManager 启动spark-shell 1234567891011121314151617181920[root@master spark-2.0.2-bin-hadoop2.6]# ./bin/spark-shell Setting default log level to &quot;WARN&quot;.To adjust logging level use sc.setLogLevel(newLevel).18/06/26 00:57:35 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable18/06/26 00:57:41 WARN spark.SparkContext: Use an existing SparkContext, some configuration may not take effect.Spark context Web UI available at http://192.168.146.129:4040Spark context available as &#x27;sc&#x27; (master = local[*], app id = local-1529999859799).Spark session available as &#x27;spark&#x27;.Welcome to ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ &#x27;_/ /___/ .__/\\_,_/_/ /_/\\_\\ version 2.0.2 /_/ Using Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_67)Type in expressions to have them evaluated.Type :help for more information.scala&gt; 验证spark 本地模式： – ]# ./bin/run-example SparkPi 10 --master local[2] 集群模式 Spark Standalone： – ]# ./bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://master:7077 examples/jars/spark-examples_2.11-2.0.2.jar 100 集群模式 Spark on Yarn集群上yarn-cluster模式： – ]# ./bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn-cluster examples/jars/spark-examples_2.11-2.0.2.jar 10 验证spark on yarn 。 配置spark connect hive 因为需要在spark里调用sparksql。所以需要spark 访问hive数据。 需要将hive-site.xml 拷贝到spark 的conf 目录下。 1cp /usr/local/src/apache-hive-1.2.2-bin/conf/hive-site.xml /usr/local/src/spark-2.0.2-bin-hadoop2.6/conf/ 将对应的mysql-connector-java-5.1.44-bin.jar 放到$SPARK_HOME/jars/目录下。 1cp /usr/local/src/mysql-connector-java-5.1.41/mysql-connector-java-5.1.41-bin.jar /usr/local/src/spark-2.0.2-bin-hadoop2.6/jars/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"http://example.com/tags/spark/"}]},{"title":"HDFS Architecture(HDFS 架构)","slug":"HDFS-Architecture-HDFS-架构","date":"2022-04-13T11:22:06.000Z","updated":"2022-04-13T11:23:56.000Z","comments":true,"path":"2022/04/13/HDFS-Architecture-HDFS-架构/","link":"","permalink":"http://example.com/2022/04/13/HDFS-Architecture-HDFS-%E6%9E%B6%E6%9E%84/","excerpt":"","text":"HDFS有一个主/从架构，一个HDFS集群由一个单一的NameNode，它是管理文件系统命名空间的主服务器，并管理客户对文件的访问。NameNode执行文件系统命名空间操作，如打开，关闭和重命名文件和目录。它还确定块到DataNode的映射关系。 此外，还有许多的DataNode(通常每个节点一个)，它们管理所在的节点的数据存储。DataNodes负责处理来自Clients的读写请求。同时再NameNode的指令下执行Block的创建，删除，复制。 HDFS 公开一个命名空间，允许用户数据存储再文件中。再内部文件被分割成一个或者多个数据块，这些数据块存储再DataNode集群中。 典型的HDFS集群，会有一个专用的机器来运行NameNode，其他机器都运行一个DataNode实例。 Note: 集群中单个NameNode的存在极大地简化了系统的架构，NameNode是所有HDFS元数据的仲裁器和存储库。用户的数据是永远不会通过NameNode。 文件系统命名空间 HDFS的文件系统类似于传统的分层结构，用户同样可以创建目录并且在目录下创建文件、删除文件，移动文件或者重命名文件. HDFS2.6.5目前还不支持对用户进行分配额度或者访问权限，以及文件间的软硬链接。未来可能会有这种功能。 NameNode维护文件系统命名空间，对其的任何更改都会进行记录。 可以指定一个文件的副本数量。一般为3份。 文件的拷贝数称为文件的复制因子。可以由参数指定。 数据复制(Data Replication) HDFS在集群中存储大文件，将每个文件存储为快序列。一个文件的所有的块除了最后一个block 其他的block 都是一样的大小。 每个文件的复制因子(备份) 的数量是可以指定的。 副本放置策略 HDFS的数据复制对提高其可靠性和性能至关重要。 机架感知策略 比如副本数量指定为3时。 HDFS的放置策略是将一个副本放在本地机架的一个node上，另一个副本放在本地机架的另一个node上。最后一个副本放在另一个机架的另一个节点上。 这种策略减少了机架间的写流量，提高写性能。机架间的故障概率远小于节点故障的概率。这个策略，文件的副本就不会均匀分布再各个机架上。三分之一的副本再一个节点上，三分之二的副本再一个架子上，另外三分之一均匀分布在剩下的架子上。 这种策略改进了写性能，而不影响数据可靠性或读性能。 副本选择 为了最小化带宽消耗和读取延迟，在一个读取请求过来的时候，如果在读取节点所在机架上存在一个请求的副本，那么这个副本更适合提供读取请求。 安全模式 在集群启动的时候，NameNode会进入一种Safemode(安全模式)的特殊状态。这时候是不会发生数据库复制的。只有当NameNode接收到DataNodes的心跳和block report后。 Block报告包含DataNodes管理的所有的数据块的列表。NameNode会检查数据块的最小复制数、在检查数据快复制百分比之后。退出安全模式。 这时候确定仍然少于指定的副本数量。NameNode 会将这些块按照对应的策略复制到其他的DataNode。","categories":[],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://example.com/tags/Hadoop/"}]},{"title":"blog test","slug":"blog-test","date":"2022-04-13T06:09:24.000Z","updated":"2022-04-13T06:09:26.000Z","comments":true,"path":"2022/04/13/blog-test/","link":"","permalink":"http://example.com/2022/04/13/blog-test/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2022-04-12T10:03:52.260Z","updated":"2022-04-12T10:03:54.000Z","comments":true,"path":"2022/04/12/hello-world/","link":"","permalink":"http://example.com/2022/04/12/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"http://example.com/tags/Oracle/"},{"name":"spark","slug":"spark","permalink":"http://example.com/tags/spark/"},{"name":"Hadoop","slug":"Hadoop","permalink":"http://example.com/tags/Hadoop/"}]}